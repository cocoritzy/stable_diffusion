{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7bec93",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Coding the Sampler\n",
    "# \n",
    "# # Number of steps\n",
    "num_steps = 500\n",
    "\n",
    "def Euler_Maruyama_sampler(score_model,\n",
    "                            marginal_prob_std,\n",
    "                            diffusion_coeff,\n",
    "                            batch_size=64,\n",
    "                            x_shape=(1, 28, 28),\n",
    "                            num_steps=num_steps,\n",
    "                            device='cuda',\n",
    "                            eps=1e-3, y=None):\n",
    "    \"\"\"\n",
    "    Generate samples from score-based models with the Euler-Maruyama solver.\n",
    "\n",
    "    Parameters:\n",
    "    - score_model: A PyTorch model that represents the time-dependent score-based model.\n",
    "    - marginal_prob_std: A function that gives the standard deviation of the perturbation kernel.\n",
    "    - diffusion_coeff: A function that gives the diffusion coefficient of the SDE.\n",
    "    - batch_size: The number of samplers to generate by calling this function once.\n",
    "    - x_shape: The shape of the samples.\n",
    "    - num_steps: The number of sampling steps, equivalent to the number of discretized time steps.\n",
    "    - device: 'cuda' for running on GPUs, and 'cpu' for running on CPUs.\n",
    "    - eps: The smallest time step for numerical stability.\n",
    "    - y: Target tensor (not used in this function).\n",
    "\n",
    "    Returns:\n",
    "    - Samples.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize time and the initial sample\n",
    "    t = torch.ones(batch_size, device=device)\n",
    "    init_x = torch.randn(batch_size, *x_shape, device=device) * marginal_prob_std(t)[:, None, None, None]\n",
    "\n",
    "    # Generate time steps\n",
    "    time_steps = torch.linspace(1., eps, num_steps, device=device)\n",
    "    step_size = time_steps[0] - time_steps[1]\n",
    "    x = init_x\n",
    "\n",
    "    # Sample using Euler-Maruyama method\n",
    "    with torch.no_grad():\n",
    "        for time_step in tqdm(time_steps):\n",
    "            batch_time_step = torch.ones(batch_size, device=device) * time_step\n",
    "            g = diffusion_coeff(batch_time_step)\n",
    "            mean_x = x + (g**2)[:, None, None, None] * score_model(x, batch_time_step, y=y) * step_size\n",
    "            x = mean_x + torch.sqrt(step_size) * g[:, None, None, None] * torch.randn_like(x)\n",
    "\n",
    "    # Do not include any noise in the last sampling step.\n",
    "    return mean_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fff95ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load the pre-trained checkpoint from disk.\n",
    "# device = 'cuda' ['cuda', 'cpu'] {'type':'string'}\n",
    "ckpt = torch.load('ckpt_transformer.pth', map_location=device)\n",
    "score_model.load_state_dict(ckpt)\n",
    "\n",
    "\n",
    "########### Specify the digit for which to generate samples\n",
    "###########\n",
    "digit = 9\n",
    "###########\n",
    "###########\n",
    "\n",
    "\n",
    "\n",
    "# Set the batch size for generating samples\n",
    "sample_batch_size = 64\n",
    "# Set the number of steps for the Euler-Maruyama sampler\n",
    "num_steps = 250\n",
    "# Choose the sampler type (Euler-Maruyama, pc_sampler, ode_sampler)\n",
    "sampler = Euler_Maruyama_sampler # ['Euler_Maruyama_sampler', 'pc_sampler', 'ode_sampler'] {'type': 'raw'}\n",
    "# score_model.eval()\n",
    "\n",
    "## Generate samples using the specified sampler.\n",
    "samples = sampler(score_model,\n",
    "        marginal_prob_std_fn,\n",
    "        diffusion_coeff_fn,\n",
    "        sample_batch_size,\n",
    "        num_steps=num_steps,\n",
    "        device=device,\n",
    "        y=digit*torch.ones(sample_batch_size, dtype=torch.long))\n",
    "\n",
    "## Sample visualization.\n",
    "samples = samples.clamp(0.0, 1.0)\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "# Create a grid of samples for visualization\n",
    "sample_grid = make_grid(samples, nrow=int(np.sqrt(sample_batch_size)))\n",
    "\n",
    "# Plot the generated samples\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.axis('off')\n",
    "plt.imshow(sample_grid.permute(1, 2, 0).cpu(), vmin=0., vmax=1.)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
